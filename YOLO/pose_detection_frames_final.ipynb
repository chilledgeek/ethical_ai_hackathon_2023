{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gpSJdnayyyjn",
    "outputId": "74fa767c-8212-4d36-af59-a5defcc59c7e"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83nWri9vy3Hj"
   },
   "outputs": [],
   "source": [
    "! [ ! -z \"$COLAB_GPU\" ] && pip install torch torchvision pillow==7.1.2 skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WK8HaHJty923",
    "outputId": "15bd784a-915e-4e40-cefd-d2b27f551b59"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# import skorch\n",
    "#Â from skorch.callbacks import LRScheduler, Checkpoint\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "# from skorch import NeuralNetClassifier\n",
    "from sklearn.metrics import accuracy_score, top_k_accuracy_score, confusion_matrix\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JZeNHYu3z2oL",
    "outputId": "279a06c9-29e8-4b33-cbce-a19ea47d542d"
   },
   "outputs": [],
   "source": [
    "%pip install ultralytics\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ag4yXDGRz9i9"
   },
   "source": [
    "Videos of interest\n",
    "- joke1.1_5dcc826c-e70a-4c28-bd4e-dca0e9023fa8_1560890971288_431.mp4\n",
    "- joke1.1_5dcc826c-e70a-4c28-bd4e-dca0e9023fa8_1560890971288_431.mp4\n",
    "- joke5.3_f4e620b4-8cf1-485a-961b-3a0828415ec5_1577919787295_189.mp4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7Bmtm_BrA61y",
    "outputId": "b1873638-c7fd-48ce-b48f-6f260f5d70e8"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO('yolov8n-pose.pt')\n",
    "\n",
    "# Open the video file\n",
    "video_paths = ['joke1.1_5dcc826c-e70a-4c28-bd4e-dca0e9023fa8_1560890971288_431.mp4']\n",
    "              # 'joke1.1_5dcc826c-e70a-4c28-bd4e-dca0e9023fa8_1560890971288_431.mp4',\n",
    "              # 'joke5.3_f4e620b4-8cf1-485a-961b-3a0828415ec5_1577919787295_189.mp4'\n",
    "for video_path in video_paths:\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Loop through the video frames\n",
    "    while cap.isOpened():\n",
    "        # Read a frame from the video\n",
    "        success, frame = cap.read()\n",
    "\n",
    "        if success:\n",
    "            # Run YOLOv8 inference on the frame\n",
    "            results = model(frame)\n",
    "\n",
    "            # Visualize the results on the frame\n",
    "            annotated_frame = results[0].plot()\n",
    "\n",
    "            # Display the annotated frame\n",
    "            cv2_imshow(annotated_frame)\n",
    "\n",
    "            # Break the loop if 'q' is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "        else:\n",
    "            # Break the loop if the end of the video is reached\n",
    "            break\n",
    "\n",
    "    # Release the video capture object and close the display window\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7oQT5QSJ5BCa",
    "outputId": "f785add7-ec74-489e-cf73-df3e1e4fdf57"
   },
   "outputs": [],
   "source": [
    "for result in results:\n",
    "  print(result.keypoints.cpu().numpy().xy)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
